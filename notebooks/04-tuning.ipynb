{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression tuning\n",
    "\n",
    "Data were originally tuned in `curium`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'bert_base_uncased', \n",
    "    'llama_7b', \n",
    "    # 'llama_13b',\n",
    "    'mental_bert', \n",
    "    'mental_longformer',\n",
    "]\n",
    "\n",
    "models = [\n",
    "    'llama3_8b', \n",
    "    'llama3_8b_instruct', \n",
    "    'llama_13b'\n",
    "]\n",
    "\n",
    "datas = [\n",
    "    'all', \n",
    "    'pt_noshort', \n",
    "    'turns'\n",
    "]\n",
    "\n",
    "# Commented features do not converge due to <3 subjects\n",
    "features = [\n",
    "    'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', # 'a8', \n",
    "    'b1', 'b2', 'b3', \n",
    "    'c1', 'c2', 'c3', 'c4', \n",
    "    'd1', 'd2', 'd3', 'd4', 'd5', 'd6', \n",
    "    'e1', 'e2', 'e3', # 'e4', # 'e5', \n",
    "    'f1', 'f2', 'f3',\n",
    "    'g1', 'g2', \n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', \n",
    "    'any'\n",
    "]\n",
    "\n",
    "k = 4\n",
    "C_list = [\n",
    "    0.0001, 0.0005, \n",
    "    0.001, 0.005, \n",
    "    0.01, 0.05, \n",
    "    0.1, 0.5, \n",
    "    1., 5., \n",
    "    10., 50., \n",
    "    100., 500., \n",
    "    1000., 5000.\n",
    "]\n",
    "\n",
    "trn_types = ['baseline', 'perm_trn']\n",
    "trn_types = ['baseline']\n",
    "\n",
    "read_dir = '/data/MLDSST/xinaw/impactme/results/raw'\n",
    "write_dir = '/data/MLDSST/xinaw/impactme/results/tuned'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning\n",
    "\n",
    "Tuning selects the best C value for each fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "params = list(itertools.product(trn_types, models, datas, features))\n",
    "\n",
    "for trn_type, model, data, feature in params:\n",
    "    try:\n",
    "        df = pd.read_csv(f'results/roc_auc/{trn_type}/{model}-{data}-{feature}.csv')\n",
    "    # If file isn't found, continue\n",
    "    except FileNotFoundError:\n",
    "        print(f'File not found: {trn_type}, {model}-{data}-{feature}')\n",
    "        continue\n",
    "    inner_df = df[df['inner_fold'] > -1]\n",
    "    del inner_df['inner_fold']\n",
    "    inner_df = inner_df.groupby(['outer_fold', 'C']).mean()\n",
    "    outer_df = inner_df.groupby(['outer_fold']).agg(np.argmax).reset_index()\n",
    "    best_C = []\n",
    "\n",
    "    for i in outer_df['roc_auc'].values:\n",
    "        best_C.append(C_list[i])\n",
    "    outer_df['best_C'] = best_C\n",
    "    outer_df['roc_auc'] = outer_df.apply(\n",
    "        lambda row: df.loc[(df['outer_fold'] == row['outer_fold']) & (df['C'] == row['best_C']) & (df['inner_fold'] == -1)]['roc_auc'].values[0], \n",
    "        axis=1\n",
    "    )\n",
    "    outer_df['model'] = model\n",
    "    outer_df['feature'] = feature\n",
    "    outer_df['data'] = data\n",
    "    outer_df['trn_type'] = trn_type\n",
    "\n",
    "    results.append(outer_df)\n",
    "\n",
    "tuned_df = pd.concat(results)\n",
    "tuned_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "tuned_dir = Path('results/tuned')\n",
    "tuned_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tuned_df.to_csv(tuned_dir / 'roc_auc-kfold-0515.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ROC AUC values\n",
    "\n",
    "### Create the concatenated file\n",
    "\n",
    "First, a file with only the best results form each outer fold is generated. The following takes around 5 minutes to run, mostly due to the `pickle` reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "\n",
    "# Don't bother with perm_trn for now\n",
    "trn_types = ['baseline']\n",
    "params = list(itertools.product(datas, features, models, trn_types))                \n",
    "tuned = pd.read_csv('results/tuned/roc_auc-kfold-0515.csv')\n",
    "res_dir = Path('results/raw')\n",
    "k = 4\n",
    "\n",
    "concat_best = []\n",
    "\n",
    "for data, feature, model, trn_type in tqdm(params):\n",
    "\n",
    "    if not exists(res_dir / f'{trn_type}/{model}-{data}-{feature}.pkl'):\n",
    "        continue\n",
    "\n",
    "    with open(res_dir / f'{trn_type}/{model}-{data}-{feature}.pkl', 'rb') as f:\n",
    "        res = pickle.load(f)\n",
    "    res = res['outputs']\n",
    "\n",
    "    df = tuned[\n",
    "        (tuned['model'] == model) &\n",
    "        (tuned['data'] == data) &\n",
    "        (tuned['feature'] == feature) &\n",
    "        (tuned['trn_type'] == trn_type)\n",
    "    ]\n",
    "\n",
    "    temp = []\n",
    "\n",
    "    for i in range(k):\n",
    "        best_C = df[df['outer_fold'] == i]['best_C'].values[0]\n",
    "        temp.append(\n",
    "            res[\n",
    "                (res['C'] == best_C) &\n",
    "                (res['outer_fold'] == i) &\n",
    "                (res['inner_fold'] == -1)\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    temp = pd.concat(temp, ignore_index=True)\n",
    "    temp['model'] = model\n",
    "    temp['trn_type'] = trn_type\n",
    "    \n",
    "    concat_best.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_best[810].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_best_df = pd.concat(concat_best, ignore_index=True)\n",
    "concat_best_df.to_csv('results/tuned/concat-0515.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations\n",
    "\n",
    "Proceeds like the above, but within swarm, since each ROC AUC calculation takes a few seconds. Because reading the concatenated file takes a while, we should not parallelize the ROC AUC calculations too much, as it'd be uneconomical to spend so much time reading the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "config_dir = Path('/data/MLDSST/xinaw/impactme/config/roc_auc-concat')\n",
    "Path(config_dir).mkdir(exist_ok=True)\n",
    "config_paths = []\n",
    "\n",
    "params = list(itertools.product(datas, features))                \n",
    "\n",
    "for data, feature in params:\n",
    "    cfg_dat = dict(\n",
    "        data=data,\n",
    "        feature=feature,\n",
    "        models=models,\n",
    "        C_list=C_list,\n",
    "        read_dir=read_dir,\n",
    "        write_dir=write_dir, \n",
    "        trn_types=trn_types, \n",
    "    )\n",
    "    cfg_path = config_dir / f'{data}-{feature}'\n",
    "    cfg_path.write_text(json.dumps(cfg_dat, indent=2))\n",
    "    config_paths.append(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('swarm/roc_auc-concat.swarm', 'w') as f:\n",
    "    for i in config_paths:\n",
    "        f.write(f'python /data/MLDSST/xinaw/impactme/roc_auc-concat.py {i}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then concatenate the ROC AUC outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "params = list(itertools.product(datas, features))\n",
    "roc_auc_df = []          \n",
    "res_dir = Path('results/tuned/roc_auc-concat')      \n",
    "\n",
    "for data, feature in params:\n",
    "    roc_auc_df.append(pd.read_csv(res_dir / f'{data}-{feature}.csv'))\n",
    "\n",
    "roc_auc_df = pd.concat(roc_auc_df, ignore_index=True)\n",
    "roc_auc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_df.to_csv('results/tuned/roc_auc-concat.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "impactme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
