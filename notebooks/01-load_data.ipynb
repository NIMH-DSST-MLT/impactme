{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17101bbc",
   "metadata": {},
   "source": [
    "# Reading data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d97d8",
   "metadata": {},
   "source": [
    "## Compiling all annotations\n",
    "\n",
    "The dataset provided by DN in `/Datasets/impactme/dylan_extract` was copied into the working directory as `data/labeled`. \n",
    "\n",
    "Currently, each label is split across multiple TSVs (27 subdomains + 8 domains + 1 ANY feature). To match the previous workflow, we want to create a table with the text, and each column corresponding to the annotation. E.g., one table with 1 + 27 + 8 + 1 columns\n",
    "\n",
    "Below is an example of how the A1 annotations for all may look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data/labeled/a1.tsv for demo\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/labeled/all/a1.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check: make sure that the column \"text\" for each TSV in data/labeled/all/ is identical\n",
    "# If not, we need to reprocess the data\n",
    "\n",
    "# Read all TSVs in data/labeled/all/\n",
    "import pandas as pd\n",
    "\n",
    "features = [\n",
    "    'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8',\n",
    "    'b1', 'b2', 'b3',\n",
    "    'c1', 'c2', 'c3', 'c4', \n",
    "    'd1', 'd2', 'd3', 'd4', 'd5', 'd6',\n",
    "    'e1', 'e2', 'e3', 'e4', 'e5',\n",
    "    'f1', 'f2', 'f3', \n",
    "    'g1', 'g2', \n",
    "]\n",
    "\n",
    "all_tsv = {\n",
    "    f: pd.read_csv(f'data/labeled/all/{f}.tsv', sep='\\t') for f in features\n",
    "}\n",
    "\n",
    "# Check if all \"text\" columns are identical\n",
    "for f in features:\n",
    "    if not all_tsv['a1']['text'].equals(all_tsv[f]['text']):\n",
    "        print(f'Column \"text\" in {f} is different from a1')\n",
    "\n",
    "# If all \"text\" columns are identical, we can create the new data frame\n",
    "# We can copy A1 and add the other columns\n",
    "df = all_tsv['a1'].copy()\n",
    "df = df.rename(columns={'positive': 'a1'})\n",
    "df['a1'] = df['a1'].astype(int)\n",
    "\n",
    "for f in features[1:]:\n",
    "    df[f] = all_tsv[f]['positive'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return elements of 'text' that are 3 characters long\n",
    "df[df['text'].str.len() < 4]['text'].unique()\n",
    "\n",
    "# Return unique combinations of subject and reporter from the above\n",
    "# df[df['text'].str.len() == 2][['subject', 'reporter']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb8626",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "# Drop the rows where str length is less than 4\n",
    "df = df[df['text'].str.len() >= 4]\n",
    "# Get number of rows\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14552778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns 'a', 'b', 'c', 'd', 'e', 'f', 'g' and 'all'\n",
    "# They need to be remade, as there was a mistake in the data collection\n",
    "# Column is is an ANY on a1, a2, ..., a8. Same rule applies to the other letters\n",
    "\n",
    "letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g']\n",
    "\n",
    "for l in letters:\n",
    "    # Select all columns that start with the letter\n",
    "    cols = [c for c in df.columns if c.startswith(l)]\n",
    "    df[l] = df[cols].any(axis=1).astype(int)\n",
    "\n",
    "# Can recreate the column 'all' as an ANY on a, b, c, d, e, f, g\n",
    "df['any'] = df[letters].any(axis=1).astype(int)\n",
    "\n",
    "# Write as text_anno\n",
    "df.to_csv('data/text_anno.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c9988",
   "metadata": {},
   "source": [
    "### Holdout list\n",
    "\n",
    "The set of holdout patients was manually developed by Dylan based on picking a subset of holdouts that showed a similar distribution of symptom occurrence per reporter. Dylan's reasoning can be found in the Slack channel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dfb5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdouts = [\n",
    "    'BEH2360',\n",
    "    'TAV2103',\n",
    "    'ISL2227',\n",
    "    'BEH2357',\n",
    "    'ISL2224',\n",
    "    'BEH2303',\n",
    "    'TAV2139',\n",
    "    'TAV2101'\n",
    "]\n",
    "\n",
    "tst = df[df[\"subject\"].isin(holdouts)]\n",
    "trn = df[-df[\"subject\"].isin(holdouts)]\n",
    "\n",
    "# Sum each column for tst and trn\n",
    "tst_sum = tst[features].sum()\n",
    "trn_sum = trn[features].sum()\n",
    "\n",
    "# Create a new data frame with the sums\n",
    "df_sum = pd.DataFrame([trn_sum, tst_sum], index=['trn', 'tst']).T\n",
    "df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.to_csv(\"data/tst/all.tsv\", sep=\"\\t\")\n",
    "trn.to_csv(\"data/trn/all.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226a407",
   "metadata": {},
   "source": [
    "### Repeating for other datasets\n",
    "\n",
    "We will repeat basically the same steps as above on `pt_noshort` and `turns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d79328",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8',\n",
    "    'b1', 'b2', 'b3',\n",
    "    'c1', 'c2', 'c3', 'c4', \n",
    "    'd1', 'd2', 'd3', 'd4', 'd5', 'd6',\n",
    "    'e1', 'e2', 'e3', 'e4', 'e5',\n",
    "    'f1', 'f2', 'f3', \n",
    "    'g1', 'g2', \n",
    "    # 'a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
    "    # 'all'\n",
    "]\n",
    "\n",
    "letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g']\n",
    "\n",
    "def write_tsvs(df, holdouts, fname):\n",
    "    tst = df[df[\"subject\"].isin(holdouts)]\n",
    "    trn = df[-df[\"subject\"].isin(holdouts)]\n",
    "\n",
    "    tst.to_csv(f\"data/tst/{fname}.tsv\", sep=\"\\t\")\n",
    "    trn.to_csv(f\"data/trn/{fname}.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190495c3",
   "metadata": {},
   "source": [
    "\n",
    "#### pt_noshort\n",
    "\n",
    "Even though this dataset is pronounced 'patient no short', it really takes the non-interviewers. \n",
    "\n",
    "The cutoff is 13 characters (that is, include everything with 13 characters or more), as this is the shortest positive example found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70274952",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptns_tsv = {\n",
    "    f: pd.read_csv(f'data/labeled/pt_noshort/{f}.tsv', sep='\\t') for f in features\n",
    "}\n",
    "\n",
    "# Check if all \"text\" columns are identical\n",
    "for f in features:\n",
    "    if not ptns_tsv['a1']['text'].equals(ptns_tsv[f]['text']):\n",
    "        print(f'Column \"text\" in {f} is different from a1')\n",
    "\n",
    "df = ptns_tsv['a1'].copy()\n",
    "df = df.rename(columns={'positive': 'a1'})\n",
    "df['a1'] = df['a1'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the other columns\n",
    "for f in features[1:]:\n",
    "    df[f] = ptns_tsv[f]['positive'].astype(int)\n",
    "\n",
    "for l in letters:\n",
    "    cols = [c for c in df.columns if c.startswith(l)]\n",
    "    df[l] = df[cols].any(axis=1).astype(int)\n",
    "\n",
    "temp = pd.read_csv('data/labeled/pt_noshort/all.tsv', sep='\\t')\n",
    "df['any'] = temp['positive'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad97cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum each column for tst and trn\n",
    "tst = df[df[\"subject\"].isin(holdouts)]\n",
    "trn = df[-df[\"subject\"].isin(holdouts)]\n",
    "tst_sum = tst[features].sum()\n",
    "trn_sum = trn[features].sum()\n",
    "\n",
    "# Create a new data frame with the sums\n",
    "df_sum = pd.DataFrame([trn_sum, tst_sum], index=['trn', 'tst']).T\n",
    "df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed165a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sum of features\n",
    "pd.DataFrame([df[letters].sum()], index=['all'])\n",
    "pd.DataFrame([df[features].sum()], index=['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d6dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43693702",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsvs(df, holdouts, \"pt_noshort\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99738a05",
   "metadata": {},
   "source": [
    "#### Turns\n",
    "\n",
    "A turn in conversation is, ideally, the interviewer and then the patient. Due to quirks in the data, in practice it's more like a chunk that starts with an interviewer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21daa9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the above, but 'turns' instead of 'pt_noshort'\n",
    "turns_tsv = {\n",
    "    f: pd.read_csv(f'data/labeled/turns/{f}.tsv', sep='\\t') for f in features\n",
    "}\n",
    "\n",
    "for f in features:\n",
    "    if not turns_tsv['a1']['text'].equals(turns_tsv[f]['text']):\n",
    "        print(f'Column \"text\" in {f} is different from a1')\n",
    "\n",
    "df = turns_tsv['a1'].copy()\n",
    "df = df.rename(columns={'positive': 'a1'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show rows that are less than 6 characters\n",
    "df[df['text'].str.len() < 7]['text'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a575bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "\n",
    "# Remove rows where 'text' is 'I: P: ' or 'I: P:'\n",
    "df = df[~df['text'].str.endswith(('I: P: ', 'I: P:'))]\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc042576",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in features[1:]:\n",
    "    df[f] = turns_tsv[f]['positive'].astype(int)\n",
    "\n",
    "for l in letters:\n",
    "    cols = [c for c in df.columns if c.startswith(l)]\n",
    "    df[l] = df[cols].any(axis=1).astype(int)\n",
    "\n",
    "df['any'] = df[letters].any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c98975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sum of features\n",
    "# pd.DataFrame([df[letters].sum()], index=['all']).T\n",
    "# pd.DataFrame([df[features].sum()], index=['all']).T\n",
    "\n",
    "write_tsvs(df, holdouts, \"turns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6378c9",
   "metadata": {},
   "source": [
    "## Passage lengths\n",
    "\n",
    "Previously performed in R but converted to Python for consistency. \n",
    "\n",
    "### Data summary\n",
    "\n",
    "After rejoining the TSVs, we can look at a basic summary table of their min, max, range, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rejoin_tsvs(fname):\n",
    "    df = pd.read_csv(f'data/trn/{fname}.tsv', sep='\\t')\n",
    "    df = pd.concat([df, pd.read_csv(f'data/tst/{fname}.tsv', sep='\\t')])\n",
    "\n",
    "    # Add column 'nchar' for number of characters in 'text'\n",
    "    df['nchar'] = df['text'].str.len()\n",
    "    df['log_nchar'] = df['nchar'].apply(lambda x: 0 if x == 0 else np.log10(x))\n",
    "    \n",
    "    return df\n",
    "\n",
    "fnames = ['all', 'pt_noshort', 'turns']\n",
    "passages = {\n",
    "    f: rejoin_tsvs(f) for f in fnames\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e13c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary tables of passages\n",
    "\n",
    "for f in fnames:\n",
    "    print(f)\n",
    "    print(passages[f].shape)\n",
    "    print('Passages w/ any feature:', passages[f]['any'].sum())\n",
    "    # Range of characters\n",
    "    print('Range of characters:', passages[f]['nchar'].min(), passages[f]['nchar'].max())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95caaf8",
   "metadata": {},
   "source": [
    "### Make histograms\n",
    "\n",
    "Histograms are faceted by the segmentation type. Additionally, positive and negative labels are plotted separately, using the feature 'any' for visual clarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec2590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a 1 x 3 grid of plots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# Paper-friendly names\n",
    "new_names = [\n",
    "    'Original', \n",
    "    'Monologue', \n",
    "    'Turns'\n",
    "]\n",
    "\n",
    "for i, f in enumerate(fnames):\n",
    "    # Plot histogram of 'log_nchar' where 'any' is 1\n",
    "    # passages[f]['log_nchar'].hist(ax=axs[i])\n",
    "    \n",
    "    # Plot histogram of 'log_nchar' where 'any' is 1\n",
    "    passages[f][passages[f]['any'] == 1]['log_nchar'].hist(\n",
    "        ax=axs[i], \n",
    "        bins=20, \n",
    "        alpha=0.5, \n",
    "        color='green',\n",
    "        label='Any feature'\n",
    "    )\n",
    "    passages[f][passages[f]['any'] == 0]['log_nchar'].hist(\n",
    "        ax=axs[i],\n",
    "        bins=20, \n",
    "        alpha=0.5, \n",
    "        color='skyblue',\n",
    "        label='No feature'\n",
    "    )   \n",
    "\n",
    "    # Fix axes to 0 to 10\n",
    "    axs[i].set_xlim(0.5, 4.0)\n",
    "\n",
    "    # Convert x-axis to 10^x\n",
    "    axs[i].set_xticks(np.arange(0.5, 4.1, 0.5))\n",
    "    axs[i].set_xticklabels([f'{10 ** x:.0f}' for x in np.arange(0.5, 4.1, 0.5)])\n",
    "\n",
    "    # Various labels\n",
    "    axs[i].set_title(new_names[i])\n",
    "    axs[i].set_xlabel('No. of characters')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "\n",
    "# Create legend at the bottom below the axis labels\n",
    "fig.legend(['Any feature', 'No feature'], loc='lower center', ncol=2, bbox_to_anchor=(0.5, -0.05))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a751bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a 1 x 3 grid of plots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# Paper-friendly names\n",
    "new_names = [\n",
    "    'Original', \n",
    "    'Monologue-like', \n",
    "    'Turns'\n",
    "]\n",
    "\n",
    "max_char = 1000\n",
    "\n",
    "for i, f in enumerate(fnames):\n",
    "    # Plot histogram of 'log_nchar' where 'any' is 1\n",
    "    # passages[f]['log_nchar'].hist(ax=axs[i])\n",
    "\n",
    "    # Fix axes to max_char\n",
    "    axs[i].set_xlim(0, max_char)\n",
    "    # Filter df by max_char\n",
    "    temp = passages[f][passages[f]['nchar'] <= max_char]\n",
    "    \n",
    "    # Plot histogram of 'log_nchar' where 'any' is 1\n",
    "    temp[temp['any'] == 1]['nchar'].hist(\n",
    "        ax=axs[i], \n",
    "        bins=20, \n",
    "        alpha=0.5, \n",
    "        color='green',\n",
    "        label='Any feature'\n",
    "    )\n",
    "    temp[temp['any'] == 0]['nchar'].hist(\n",
    "        ax=axs[i],\n",
    "        bins=20, \n",
    "        alpha=0.5, \n",
    "        color='skyblue',\n",
    "        label='No feature'\n",
    "    )   \n",
    "\n",
    "    # Various labels\n",
    "    axs[i].set_title(new_names[i])\n",
    "    axs[i].set_xlabel('No. of characters')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "\n",
    "# Create legend at the bottom below the axis labels\n",
    "fig.legend(['Any feature', 'No feature'], loc='lower center', ncol=2, bbox_to_anchor=(0.5, -0.05))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c21d6",
   "metadata": {},
   "source": [
    "## Label distribution\n",
    "\n",
    "We can display the counts of each feature for each type of data in a simple wide table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558dc87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wide table of counts of feature by each dataset\n",
    "df = pd.DataFrame()\n",
    "\n",
    "feats = features + ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'any']\n",
    "for f in fnames:\n",
    "    temp = passages[f][feats].sum()\n",
    "    temp['dataset'] = f\n",
    "    df = df.append(temp, ignore_index=True)\n",
    "\n",
    "df = df.set_index('dataset')\n",
    "\n",
    "# Replace names\n",
    "df = df.rename(index={'all': 'Original', 'pt_noshort': 'Monologue-like', 'turns': 'Turns'})\n",
    "df = df.rename(columns={f: f.upper() for f in feats})\n",
    "df.T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def1598",
   "metadata": {},
   "source": [
    "#### Compared with training\n",
    "\n",
    "We can also append columns corresponding to the number of annotations in the training set (non-holdout)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a91107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fnames = ['all', 'pt_noshort', 'turns']\n",
    "trn_passages = {\n",
    "    f: pd.read_csv(f'data/trn/{f}.tsv', sep='\\t') for f in fnames\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b5752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wide table of counts of feature by each dataset\n",
    "trn_df = pd.DataFrame()\n",
    "\n",
    "feats = features + ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'any']\n",
    "for f in fnames:\n",
    "    temp = trn_passages[f][feats].sum()\n",
    "    temp['dataset'] = f\n",
    "    trn_df = trn_df.append(temp, ignore_index=True)\n",
    "\n",
    "trn_df = trn_df.set_index('dataset')\n",
    "\n",
    "# Replace names\n",
    "trn_df = trn_df.rename(index={'all': 'Original', 'pt_noshort': 'Monologue-like', 'turns': 'Turns'})\n",
    "trn_df = trn_df.rename(columns={f: f.upper() for f in feats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f41435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb90d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make trn_df.T new columns of df.T\n",
    "all_df = df.T.join(trn_df.T, rsuffix='_trn')\n",
    "\n",
    "# Print as LaTeX\n",
    "print(all_df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b0bf6",
   "metadata": {},
   "source": [
    "## Subject number distributions\n",
    "\n",
    "Similar to above, we can create tables listing the number of unique subjects for each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0204b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentations = ['Orig', 'Mono', 'Turn']\n",
    "subj_nos_all = []\n",
    "for data in fnames:\n",
    "    temp = passages[data]\n",
    "    subj_nos = [temp[temp[feat] == 1]['subject'].nunique() for feat in feats]\n",
    "    subj_nos_all.append(subj_nos)\n",
    "subj_nos_all = np.array(subj_nos_all).T\n",
    "df = pd.DataFrame(subj_nos_all, columns=segmentations)\n",
    "# Insert feats as first column\n",
    "df.insert(0, 'Feature', feats)\n",
    "\n",
    "# Repeat for trn_df\n",
    "subj_nos_all = []\n",
    "for data in fnames:\n",
    "    temp = trn_passages[data]\n",
    "    subj_nos = [temp[temp[feat] == 1]['subject'].nunique() for feat in feats]\n",
    "    subj_nos_all.append(subj_nos)\n",
    "subj_nos_all = np.array(subj_nos_all).T\n",
    "trn_df = pd.DataFrame(subj_nos_all, columns=segmentations)\n",
    "trn_df.insert(0, 'Feature', feats)\n",
    "\n",
    "# Merge data\n",
    "all_df = df.merge(trn_df, on='Feature', suffixes=('', '1'))\n",
    "# Sort by 'Feature'\n",
    "all_df = all_df.sort_values('Feature')\n",
    "# Make Feature all upper\n",
    "all_df['Feature'] = all_df['Feature'].str.upper()\n",
    "\n",
    "# Print as LaTeX\n",
    "print(all_df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2271b0e",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "The average of the last hidden state of the model will be provided as the inputs to logistic regression. The final hidden layer has dimension $n_{tokens} \\times d_{hidden}$, where $d_{hidden} = 768$ for base BERT. The average produces a $1 \\times 768$ tensor. Alternatively, a sum of the last few layers can also be used as the inputs. \n",
    "\n",
    "As this code takes some time to run, even with GPU acceleration, the embeds are saved in the `data/trn` directory and read from the file. Embeds are generated in the 00A and 00B executables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979bd6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in a faster machine, like radium or europium\n",
    "# ! python 00A-embeds.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976bf659",
   "metadata": {},
   "source": [
    "### BERT embedding distribution\n",
    "\n",
    "To get an idea of the structure of the data, a heatmap of the embeddings is provided below. \n",
    "\n",
    "To be visually informative, the range of the heatmap is roughly the mean plus or minus 1.5 standard deviations. The heatmap shows banding; this may be the result of divisions between the patient IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "with open('data/trn/bert_base_uncased-last_avg-all.t','rb') as f:\n",
    "    embeds = torch.load(f)\n",
    "\n",
    "embeds_np = embeds.cpu().numpy()\n",
    "\n",
    "print(\n",
    "    np.min(embeds_np), \n",
    "    np.max(embeds_np),\n",
    "    np.mean(embeds_np),\n",
    "    np.std(embeds_np)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ded828",
   "metadata": {},
   "source": [
    "Adding lines indicating the patient and reporter type boundaries does show that banding is correlated with the ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee11a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "text_anno = pd.read_csv(\"data/trn/all.tsv\", sep=\"\\t\")\n",
    "text_id = text_anno[\"subject\"].values\n",
    "text_type = text_anno[\"reporter\"].values\n",
    "\n",
    "id_idx = [i for i, (a, b) in enumerate(zip(text_id, text_id[1:]), 1) if a != b]\n",
    "type_idx = [i for i, (a, b) in enumerate(zip(text_type, text_type[1:]), 1) if a != b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e113623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "plt.imshow(embeds_np, vmin=-.5, vmax=.5, aspect=.05)\n",
    "plt.colorbar()\n",
    "plt.hlines(y=id_idx, xmin=0, xmax=150, color='r', linestyle='-', linewidth=0.5)\n",
    "plt.hlines(y=id_idx, xmin=618, xmax=767, color='r', linestyle='-', linewidth=0.5)\n",
    "plt.hlines(y=type_idx, xmin=151, xmax=617, color='w', linestyle='--', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f8c8a",
   "metadata": {},
   "source": [
    "We can also group together all the reporters from the same ID. The reason why we're writing a dictionary and concatenating the values is because using `np.argsort` straightforwardly results in scrambling of the secondary grouping by type, rather than keeping transcripts from the same reporter in the same chunk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed5bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = text_anno['subject'].unique()\n",
    "id_grouped = [np.where(text_id == i)[0] for i in unique_ids]\n",
    "\n",
    "text_id = text_anno[\"subject\"].values\n",
    "text_type = text_anno[\"reporter\"].values\n",
    "\n",
    "type_list = ['y', 'p', 't']\n",
    "id_dict = {}\n",
    "\n",
    "for i in unique_ids:\n",
    "    id_dict[i] = {}\n",
    "    for t in type_list:\n",
    "        id_dict[i][t] = np.where((text_id == i) & (text_type == t))[0]\n",
    "\n",
    "id_grouped = []\n",
    "\n",
    "for i in id_dict:\n",
    "    temp = [id_dict[i][t] for t in type_list]\n",
    "    temp = np.concatenate(temp)\n",
    "    id_grouped.append(temp)\n",
    "id_grouped = np.concatenate(id_grouped)\n",
    "\n",
    "text_id = text_id[id_grouped]\n",
    "text_type = text_type[id_grouped]\n",
    "\n",
    "id_idx = [i for i, (a, b) in enumerate(zip(text_id, text_id[1:]), 1) if a != b]\n",
    "type_idx = [i for i, (a, b) in enumerate(zip(text_type, text_type[1:]), 1) if a != b]\n",
    "\n",
    "embeds_grouped = embeds_np[id_grouped]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "plt.imshow(embeds_grouped, vmin=-.5, vmax=.5, aspect=.05)\n",
    "plt.colorbar()\n",
    "plt.hlines(y=id_idx, xmin=0, xmax=150, color='r', linestyle='-', linewidth=0.5)\n",
    "plt.hlines(y=id_idx, xmin=618, xmax=767, color='r', linestyle='-', linewidth=0.5)\n",
    "plt.hlines(y=type_idx, xmin=151, xmax=450, color='w', linestyle='--', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c1e6e",
   "metadata": {},
   "source": [
    "### Comparing embeddings from different models\n",
    "\n",
    "We can repeat the code above to compare the embeddings across BERT base uncased, mental BERT, and mental longformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'bert_base_uncased',\n",
    "    'mental_bert', \n",
    "    'roberta'\n",
    "]\n",
    "text_anno = pd.read_csv(\"data/trn/all.tsv\", sep=\"\\t\")\n",
    "embeds = {}\n",
    "\n",
    "for model in models:\n",
    "    with open(f'data/trn/{model}-last_avg-all.t','rb') as f:\n",
    "        x = torch.load(f)\n",
    "\n",
    "    # Convert embeddings to numpy\n",
    "    x = x.cpu().numpy()\n",
    "\n",
    "    unique_ids = text_anno[\"subject\"].unique()\n",
    "    id_grouped = [np.where(text_id == i)[0] for i in unique_ids]\n",
    "\n",
    "    text_id = text_anno[\"subject\"].values\n",
    "    text_type = text_anno[\"reporter\"].values\n",
    "\n",
    "    type_list = [\"y\", \"p\", \"t\"]\n",
    "    id_dict = {}\n",
    "\n",
    "    for i in unique_ids:\n",
    "        id_dict[i] = {}\n",
    "        for t in type_list:\n",
    "            id_dict[i][t] = np.where((text_id == i) & (text_type == t))[0]\n",
    "\n",
    "    id_grouped = []\n",
    "\n",
    "    for i in id_dict:\n",
    "        temp = [id_dict[i][t] for t in type_list]\n",
    "        temp = np.concatenate(temp)\n",
    "        id_grouped.append(temp)\n",
    "    id_grouped = np.concatenate(id_grouped)\n",
    "\n",
    "    text_id = text_id[id_grouped]\n",
    "    text_type = text_type[id_grouped]\n",
    "\n",
    "    id_idx = [i for i, (a, b) in enumerate(zip(text_id, text_id[1:]), 1) if a != b]\n",
    "    type_idx = [i for i, (a, b) in enumerate(zip(text_type, text_type[1:]), 1) if a != b]\n",
    "\n",
    "    embeds[model] = x[id_grouped]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfdfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make table of summary stats (mean, std, min, max) for each feature\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "embeds_df = []\n",
    "\n",
    "for model in models:\n",
    "    embeds_np = embeds[model]\n",
    "    # print(model)\n",
    "    # print(\n",
    "    #     np.min(embeds_np), \n",
    "    #     np.max(embeds_np),\n",
    "    #     np.mean(embeds_np),\n",
    "    #     np.std(embeds_np)\n",
    "    # )\n",
    "    temp = pd.DataFrame({\n",
    "        'model': model,\n",
    "        'min': [np.min(embeds_np)],\n",
    "        'max': [np.max(embeds_np)],\n",
    "        'mean': [np.mean(embeds_np)],\n",
    "        'std': [np.std(embeds_np)]\n",
    "    })\n",
    "    embeds_df.append(temp)\n",
    "\n",
    "embeds_df = pd.concat(embeds_df, ignore_index=True)\n",
    "embeds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e187851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the embeddings side by side\n",
    "fig, axs = plt.subplots(1, 3, figsize=(30, 10))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    axs[i].imshow(embeds[model], vmin=-.5, vmax=.5, aspect=.05)\n",
    "    axs[i].set_title(model)\n",
    "    axs[i].hlines(y=id_idx, xmin=0, xmax=150, color='r', linestyle='-', linewidth=0.5)\n",
    "    axs[i].hlines(y=id_idx, xmin=618, xmax=767, color='r', linestyle='-', linewidth=0.5)\n",
    "    axs[i].hlines(y=type_idx, xmin=151, xmax=450, color='w', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Title\n",
    "    axs[i].set_title(model)\n",
    "    # Add colorbar\n",
    "    cbar = axs[i].figure.colorbar(axs[i].images[0], ax=axs[i])\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e0c6f",
   "metadata": {},
   "source": [
    "## Text examples\n",
    "\n",
    "To get an idea of the components of the data, we will list unique passages (adjusted to be all lowercase) from each symptom (and also divided by positive and negative). These examples will be saved in `/Datasets/impactme/text_ex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d035e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "text_anno = pd.read_csv(\"data/text_anno.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in text_anno.columns[5:]:\n",
    "    # Sort the examples by pos/neg label and length\n",
    "    # and make sure they're unique\n",
    "    pos = text_anno[text_anno[s] == 1][\"quote_t\"].values\n",
    "    pos = sorted(list(set([s.lower() for s in pos])), key=len)\n",
    "\n",
    "    neg = text_anno[text_anno[s] == 0][\"quote_t\"].values\n",
    "    neg = sorted(list(set([s.lower() for s in neg])), key=len)\n",
    "\n",
    "    # Save text files in `/Datasets/impactme/text_ex`\n",
    "    with open(f\"/Datasets/impactme/text_ex/{s}_pos.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(pos))\n",
    "    with open(f\"/Datasets/impactme/text_ex/{s}_neg.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(neg))\n",
    "\n",
    "    # Print some examples\n",
    "    print(f\"{s} pos: {pos[:5]}\")\n",
    "    print(f\"{s} neg: {neg[:11]}\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfcf8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the most common short neg text\n",
    "from collections import Counter\n",
    "\n",
    "# Concatenate together all the negative examples from a1_mood...a8_comorbid\n",
    "neg_text = []\n",
    "\n",
    "for s in text_anno.columns[5:]:\n",
    "    neg = text_anno[text_anno[s] == 0][\"quote_t\"].values\n",
    "    neg = sorted(list(set([s.lower() for s in neg])), key=len)\n",
    "    neg_text += neg\n",
    "\n",
    "# Get the counts for each element\n",
    "neg_counts = Counter(neg_text)\n",
    "\n",
    "# Repeat for positive examples\n",
    "pos_text = []\n",
    "\n",
    "for s in text_anno.columns[5:]:\n",
    "    pos = text_anno[text_anno[s] == 1][\"quote_t\"].values\n",
    "    pos = sorted(list(set([s.lower() for s in pos])), key=len)\n",
    "    pos_text += pos\n",
    "\n",
    "pos_counts = Counter(pos_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67704522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write counts to a tab-separated text file\n",
    "# Headers: text, count\n",
    "with open(\"/Datasets/impactme/text_ex/neg_counts.tsv\", \"w\") as f:\n",
    "    f.write(\"text\\tcount\\n\")\n",
    "    for k, v in neg_counts.most_common():\n",
    "        f.write(f\"{k}\\t{v}\\n\")\n",
    "\n",
    "with open(\"/Datasets/impactme/text_ex/pos_counts.tsv\", \"w\") as f:\n",
    "    f.write(\"text\\tcount\\n\")\n",
    "    for k, v in pos_counts.most_common():\n",
    "        f.write(f\"{k}\\t{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2952d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pos_counts, write the Counter to a pnadas DataFrame and sort by count\n",
    "pos_df = pd.DataFrame.from_dict(pos_counts, orient='index')\n",
    "pos_df.reset_index(inplace=True)\n",
    "pos_df.columns = ['text', 'total']\n",
    "\n",
    "# Create a new column for each symptom indicating whether the text appears\n",
    "for s in text_anno.columns[5:]:\n",
    "    pos = text_anno[text_anno[s] == 1][\"quote_t\"].values\n",
    "    pos = sorted(list(set([s.lower() for s in pos])), key=len)\n",
    "    pos_df[s] = pos_df['text'].isin(pos).astype(int)\n",
    "\n",
    "# insert column for number of characters in the text at index 1\n",
    "pos_df.insert(1, 'nchar', pos_df['text'].str.len())\n",
    "# Sort by the number of characters in the text column (ascending order)\n",
    "pos_df = pos_df.sort_values(by=['total', 'nchar'], ascending=[False, True])\n",
    "\n",
    "# Write pandas df to a tab-separated text file at `/Datasets/impactme/text_ex/pos_counts_all.tsv`\n",
    "with open(\"/Datasets/impactme/text_ex/pos_counts_all.tsv\", \"w\") as f:\n",
    "    pos_df.to_csv(f, sep=\"\\t\", index=False)\n",
    "\n",
    "# Repeat the above for negative counts\n",
    "neg_df = pd.DataFrame.from_dict(neg_counts, orient='index')\n",
    "neg_df.reset_index(inplace=True)\n",
    "neg_df.columns = ['text', 'total']\n",
    "\n",
    "for s in text_anno.columns[5:]:\n",
    "    neg = text_anno[text_anno[s] == 0][\"quote_t\"].values\n",
    "    neg = sorted(list(set([s.lower() for s in neg])), key=len)\n",
    "    neg_df[s] = neg_df['text'].isin(neg).astype(int)\n",
    "\n",
    "neg_df.insert(1, 'nchar', neg_df['text'].str.len())\n",
    "neg_df = neg_df.sort_values(by=['total', 'nchar'], ascending=[False, True])\n",
    "\n",
    "with open(\"/Datasets/impactme/text_ex/neg_counts_all.tsv\", \"w\") as f:\n",
    "    neg_df.to_csv(f, sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1fb1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df.sort_values(by='nchar', ascending=True).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df.sort_values(by='nchar', ascending=True).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e20372",
   "metadata": {},
   "source": [
    "## Notes on the other datasets\n",
    "\n",
    "As of a meeting regarding BERT learning (October 4, 2023), the dataset will be adjusted in an effort to make training more informative. \n",
    "\n",
    "The following modifications have been proposed: \n",
    "\n",
    "- Only using passates with more than 12 characters\n",
    "- Patient passages only\n",
    "- Patient passages with more than 12 characters\n",
    "- Interview-patient cycles instead of individual turns (no eliminatation entries here to preserve the turns)\n",
    "\n",
    "The cutoff of 12 characters was chosen because the shortest positively labeled passage is 13 characters long. \n",
    "\n",
    "The datasets without modifications are saved in `data/trn/all.tsv` and `data/tst/all.tsv`.\n",
    "\n",
    "We will be using the same set of holdouts as identified previously. \n",
    "\n",
    "As of 2024 Feb 22, the code used to create these datasets have been deleted, as the task was outsourced to Dylan. \n",
    "\n",
    "The data with only non-interviewer entries more than 12 characters is `pt_noshort`. Labeling of full turns of conversation is `turns`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c286d141",
   "metadata": {},
   "source": [
    "## LLama embeds\n",
    "\n",
    "Llama embeds were generated on the original, uncleaned data. We can gather the correct indices to drop for each data type (all, pt_noshort, and turns) using the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29f83f",
   "metadata": {},
   "source": [
    "### Dropped rows\n",
    "\n",
    "The basic premise is that Llama embeds need to be converted into tensors for training and test sets. \n",
    "\n",
    "We need to collect the indices for:\n",
    "\n",
    "1. Dropped rows (empty lines in transcript)\n",
    "2. Retained and holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of indices in a1.tsv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f2f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "datas = [\n",
    "    'all',\n",
    "    'pt_noshort',\n",
    "    'turns'\n",
    "]\n",
    "\n",
    "holdouts = [\n",
    "    'BEH2360',\n",
    "    'TAV2103',\n",
    "    'ISL2227',\n",
    "    'BEH2357',\n",
    "    'ISL2224',\n",
    "    'BEH2303',\n",
    "    'TAV2139',\n",
    "    'TAV2101'\n",
    "]\n",
    "\n",
    "keep_indices = {d: [] for d in datas}\n",
    "\n",
    "### 'all' ###\n",
    "\n",
    "# Get indices where the text is more than or equal to 4 characters\n",
    "df = pd.read_csv('data/labeled/all/a1.tsv', sep='\\t')\n",
    "drop = np.where(df['text'].str.len() < 4)[0]\n",
    "\n",
    "trn_ind = np.where(~df['subject'].isin(holdouts))[0]\n",
    "trn_ind = np.setdiff1d(trn_ind, drop)\n",
    "keep_indices['all'].append(trn_ind)\n",
    "\n",
    "tst_ind = np.where(df['subject'].isin(holdouts))[0]\n",
    "tst_ind = np.setdiff1d(tst_ind, drop)\n",
    "keep_indices['all'].append(tst_ind)\n",
    "\n",
    "print('all:')\n",
    "print(f'{len(trn_ind)} rows in trn, {len(tst_ind)} rows in tst')\n",
    "\n",
    "### 'pt_noshort' ###\n",
    "\n",
    "df = pd.read_csv('data/labeled/pt_noshort/a1.tsv', sep='\\t')\n",
    "# No need for drops because it's already < 13 char)\n",
    "trn_ind = np.where(~df['subject'].isin(holdouts))[0]\n",
    "keep_indices['pt_noshort'].append(trn_ind)\n",
    "\n",
    "tst_ind = np.where(df['subject'].isin(holdouts))[0]\n",
    "keep_indices['pt_noshort'].append(tst_ind)\n",
    "\n",
    "print('pt_noshort:')\n",
    "print(f'{len(trn_ind)} rows in trn, {len(tst_ind)} rows in tst')\n",
    "\n",
    "# 'turns' ###\n",
    "\n",
    "df = pd.read_csv('data/labeled/turns/a1.tsv', sep='\\t')\n",
    "drop = np.where(df['text'].str.endswith(('I: P: ', 'I: P:')))[0]\n",
    "\n",
    "trn_ind = np.where(~df['subject'].isin(holdouts))[0]\n",
    "trn_ind = np.setdiff1d(trn_ind, drop)\n",
    "keep_indices['turns'].append(trn_ind)\n",
    "\n",
    "tst_ind = np.where(df['subject'].isin(holdouts))[0]\n",
    "tst_ind = np.setdiff1d(tst_ind, drop)\n",
    "keep_indices['turns'].append(tst_ind)\n",
    "\n",
    "print('turns:')\n",
    "print(f'{len(trn_ind)} rows in trn, {len(tst_ind)} rows in tst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5327eb44",
   "metadata": {},
   "source": [
    "### CSV to torch conversion\n",
    "\n",
    "We now translate the very inefficient CSV format to the much more compact torch format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5155455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read llama embeds from data/llama\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "datas = [\n",
    "    'all',\n",
    "    'pt_noshort', \n",
    "    'turns'\n",
    "]\n",
    "\n",
    "fnames = [\n",
    "    'Meta-Llama-3-8B', \n",
    "    'Meta-Llama-3-8B-Instruct'\n",
    "]\n",
    "\n",
    "save_names = [\n",
    "    'llama3_8b', \n",
    "    'llama3_8b_instruct'\n",
    "]\n",
    "# sizes = ['70b']\n",
    "\n",
    "# Takes around 1 m 10 s to run\n",
    "for data in datas:\n",
    "    print(f'Processing {data}...')\n",
    "    for f, save_name in zip(fnames, save_names):\n",
    "\n",
    "        # Pass if the tensor already exists\n",
    "        if f'{save_name}-last_avg-{data}.t' in os.listdir('data/trn/') and f'{save_name}-last_avg-{data}.t' in os.listdir('data/tst/'):\n",
    "            print(f'File already exists: {save_name}-last_avg-{data}.t')\n",
    "            continue\n",
    "\n",
    "        print(f'    Processing {f}...')\n",
    "        try:\n",
    "            llama = pd.read_csv(f'llama/{f}_{data}.csv', header=None)\n",
    "        except FileNotFoundError:\n",
    "            print(f'File not found: llama/{f}_{data}.csv')\n",
    "            continue\n",
    "\n",
    "        print(llama.shape)\n",
    "\n",
    "        # Convert to torch\n",
    "        llama_tensor = torch.tensor(llama.values)\n",
    "\n",
    "        llama_trn = llama_tensor[keep_indices[data][0]]\n",
    "        llama_tst = llama_tensor[keep_indices[data][1]]\n",
    "\n",
    "        with open(f'data/trn/{save_name}-last_avg-{data}.t', 'wb') as f:\n",
    "            torch.save(llama_trn, f)\n",
    "\n",
    "        with open(f'data/tst/{save_name}-last_avg-{data}.t', 'wb') as f:\n",
    "            torch.save(llama_tst, f)\n",
    "        \n",
    "        del llama, llama_tensor, llama_trn, llama_tst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655b2c6",
   "metadata": {},
   "source": [
    "### Comparing embeddings\n",
    "\n",
    "Similar to above, we can create heatmaps comparing the embeddings of BERT to the three Llama sizes. \n",
    "\n",
    "Note that this hasn't yet been done for the Llama 3 models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dde4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_anno.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0392334",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'bert_base_uncased',\n",
    "    'llama_7b',\n",
    "    'llama_13b',\n",
    "    'llama_70b',\n",
    "]\n",
    "data = 'turns'\n",
    "text_anno = pd.read_csv(f\"data/trn/{data}.tsv\", sep=\"\\t\")\n",
    "embeds = {}\n",
    "\n",
    "for model in models:\n",
    "    with open(f'data/trn/{model}-last_avg-{data}.t','rb') as f:\n",
    "        x = torch.load(f)\n",
    "\n",
    "    # Convert embeddings to numpy\n",
    "    x = x.cpu().numpy()\n",
    "\n",
    "    unique_ids = text_anno[\"subject\"].unique()\n",
    "    text_id = text_anno[\"subject\"].values\n",
    "    text_type = text_anno[\"reporter\"].values\n",
    "    id_grouped = [np.where(text_id == i)[0] for i in unique_ids]\n",
    "    type_list = [\"y\", \"p\", \"t\"]\n",
    "    id_dict = {}\n",
    "\n",
    "    for i in unique_ids:\n",
    "        id_dict[i] = {}\n",
    "        for t in type_list:\n",
    "            id_dict[i][t] = np.where((text_id == i) & (text_type == t))[0]\n",
    "\n",
    "    id_grouped = []\n",
    "\n",
    "    for i in id_dict:\n",
    "        temp = [id_dict[i][t] for t in type_list]\n",
    "        temp = np.concatenate(temp)\n",
    "        id_grouped.append(temp)\n",
    "    id_grouped = np.concatenate(id_grouped)\n",
    "\n",
    "    text_id = text_id[id_grouped]\n",
    "    text_type = text_type[id_grouped]\n",
    "\n",
    "    id_idx = [i for i, (a, b) in enumerate(zip(text_id, text_id[1:]), 1) if a != b]\n",
    "    type_idx = [i for i, (a, b) in enumerate(zip(text_type, text_type[1:]), 1) if a != b]\n",
    "\n",
    "    embeds[model] = x[id_grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6165735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the embeddings side by side\n",
    "fig, axs = plt.subplots(1, 4, figsize=(30, 10))\n",
    "\n",
    "vminlim = -1\n",
    "vmaxlim = 1\n",
    "\n",
    "axs[0].imshow(embeds['bert_base_uncased'], vmin=vminlim, vmax=vmaxlim, aspect=.1)\n",
    "axs[1].imshow(embeds['llama_7b'], vmin=vminlim, vmax=vmaxlim, aspect=0.53)\n",
    "axs[2].imshow(embeds['llama_13b'], vmin=vminlim, vmax=vmaxlim, aspect=0.67)\n",
    "axs[3].imshow(embeds['llama_70b'], vmin=vminlim, vmax=vmaxlim, aspect=1.07)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    axs[i].set_title(model)\n",
    "    axs[i].hlines(y=id_idx, xmin=0, xmax=150, color='r', linestyle='-', linewidth=0.5)\n",
    "    axs[i].hlines(y=id_idx, xmin=618, xmax=767, color='r', linestyle='-', linewidth=0.5)\n",
    "    axs[i].hlines(y=type_idx, xmin=151, xmax=450, color='w', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Title\n",
    "    axs[i].set_title(model)\n",
    "    # Add colorbar\n",
    "    cbar = axs[i].figure.colorbar(axs[i].images[0], ax=axs[i])\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dcee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    df = embeds[model]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfabdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4)\n",
    "for ax, model in zip(axes, models):\n",
    "    ax.plot(embeds[model].std(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66cf5fb",
   "metadata": {},
   "source": [
    "## Hidden dimension and context length counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "models = [\n",
    "    'llama_7b', \n",
    "    'llama3_8b',\n",
    "    'bert_base_uncased',\n",
    "    'mental_bert', \n",
    "    'mental_longformer'\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    with open(f'data/trn/{model}-last_avg-all.t','rb') as f:\n",
    "        x = torch.load(f)\n",
    "    print(model, x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "impactme",
   "language": "python",
   "name": "impactme"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
